{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOGnCiy5D1xrNBXyq9Ce/zz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geersenthil/Topic-Modeling-/blob/main/LSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "1w85MANKPzDp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3SYRy2UDnqId"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "#Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.models import LsiModel\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#Dataset\n",
        "from sklearn.datasets import fetch_20newsgroups\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-process the data"
      ],
      "metadata": {
        "id": "_P5ElWt8RlOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(doc):\n",
        "  #init regex token\n",
        "  tokenizer =  RegexpTokenizer(r'\\w+')\n",
        "  # create stopword list\n",
        "  stop = set(stopwords.words('english'))\n",
        "  #create a port stemmer\n",
        "  p_stemmer = PorterStemmer()\n",
        "  #list for tokenized documents in loop\n",
        "  texts = []\n",
        "  for x in doc:\n",
        "    value = x.lower()\n",
        "    tokens = tokenizer.tokenize(value)\n",
        "    stopped_tokens= [y for y in tokens if not y in stop]\n",
        "\n",
        "    #tokens that aren't stop words\n",
        "    stemmed_tokens = [p_stemmer.stem(x) for x in stopped_tokens]\n",
        "\n",
        "    texts.append(stemmed_tokens)\n",
        "\n",
        "  return texts\n"
      ],
      "metadata": {
        "id": "x6ptoc_0Rk7N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data into Dataframe"
      ],
      "metadata": {
        "id": "FFk_NZmgf7jB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news_group = fetch_20newsgroups()\n",
        "\n",
        "news_group_data = news_group.data\n",
        "news_group_target_names = news_group.target_names\n",
        "news_group_target = news_group.target"
      ],
      "metadata": {
        "id": "3GeGzeMVfxOX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_df = pd.DataFrame({'news': news_group_data})\n",
        "news_data = news_df['news'].sample(100)"
      ],
      "metadata": {
        "id": "vJZSa2e-gHjs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Corpus"
      ],
      "metadata": {
        "id": "5R6Ott-ggbTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_corpus(docs):\n",
        "  #term dictionary\n",
        "  dictionary = corpora.Dictionary(docs)\n",
        "  # convert list into document matrix\n",
        "  doc_term_matrix = [dictionary.doc2bow(i) for i in docs]\n",
        "  return dictionary, doc_term_matrix\n",
        "  "
      ],
      "metadata": {
        "id": "iWPM8Gegga_1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_gensim_lsa_model(doc,num_tops,words):\n",
        "  dictionary, doc_term_matrix=prepare_corpus(doc)\n",
        "  #create LSA model\n",
        "  lsamodel =LsiModel(doc_term_matrix, num_topics= num_tops, id2word=dictionary)\n",
        "  print(lsamodel.print_topics(num_topics=num_tops,num_words=words))\n",
        "  return lsamodel"
      ],
      "metadata": {
        "id": "xr3wRTl8kHRY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import coherencemodel\n",
        "def compute_coherence_values(dictionary,doc_term_matrix,doc, stop, start= 2, step=3):\n",
        "  coherence_values = []\n",
        "  model_list = []\n",
        "  for num_topics in range(start, stop, step):\n",
        "    #generate LSA model\n",
        "    model = LsiModel(doc_term_matrix, num_topics= num_topics, id2word=dictionary)\n",
        "    model_list.append(model)\n",
        "    coherencemodel= CoherenceModel(model=model, texts=doc,dictionary=dictionary,coherence='c_v')\n",
        "    coherence_values.append(coherencemodel.get_coherence())\n",
        "    return model_list, coherence_values"
      ],
      "metadata": {
        "id": "vj3D3zEGlQbq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BnqIZXYkoHQ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}